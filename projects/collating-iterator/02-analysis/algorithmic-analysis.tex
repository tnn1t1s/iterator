\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[margin=1in]{geometry}
\usepackage{algorithm}
\usepackage{algpseudocode}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{invariant}{Invariant}

\title{Collating Iterator: Algorithmic Analysis}
\author{Research Artifact}
\date{October 2025}

\begin{document}
\maketitle

\section{Algorithm Description}

The heap-based collating iterator uses a binary min-heap to efficiently select the minimum element across $k$ sorted input iterators.

\begin{algorithm}
\caption{Heap-Based K-Way Merge}
\begin{algorithmic}[1]
\State \textbf{Initialize:}
\State $H \gets \emptyset$ \Comment{Min-heap of (element, iterator) pairs}
\For{each iterator $I_i$ in input collection}
    \If{$I_i.\texttt{hasNext()}$}
        \State $e \gets I_i.\texttt{next()}$
        \State $H.\texttt{insert}((e, I_i))$
    \EndIf
\EndFor
\State
\State \textbf{Operation hasNext():}
\State \Return $H \neq \emptyset$
\State
\State \textbf{Operation next():}
\If{$H = \emptyset$}
    \State \textbf{throw} NoSuchElementException
\EndIf
\State $(e, I) \gets H.\texttt{extractMin()}$
\If{$I.\texttt{hasNext()}$}
    \State $e' \gets I.\texttt{next()}$
    \State $H.\texttt{insert}((e', I))$
\EndIf
\State \Return $e$
\end{algorithmic}
\end{algorithm}

\section{Time Complexity}

\subsection{Per-Operation Analysis}

\begin{itemize}
    \item \textbf{hasNext()}: $O(1)$
    \begin{itemize}
        \item Simple check: $|H| > 0$
    \end{itemize}

    \item \textbf{next()}: $O(\log k)$
    \begin{itemize}
        \item extractMin(): $O(\log k)$ for heap sift-down
        \item Iterator advance: $O(1)$ amortized
        \item insert(): $O(\log k)$ for heap sift-up
        \item Total: $O(\log k)$
    \end{itemize}

    \item \textbf{Construction}: $O(k \log k)$ naive, $O(k)$ with heapify
    \begin{itemize}
        \item Naive: $k$ insertions $\times$ $O(\log k)$ = $O(k \log k)$
        \item Heapify: Build heap bottom-up in $O(k)$ [CLRS Ch 6.3]
    \end{itemize}
\end{itemize}

\subsection{Total Complexity}

Let $N = \sum_{i=0}^{k-1} |I_i|$ be the total number of elements across all iterators.

\begin{theorem}[Time Complexity]
The heap-based collating iterator processes all $N$ elements in $O(N \log k)$ time.
\end{theorem}

\begin{proof}
\begin{itemize}
    \item Each of $N$ elements passes through \texttt{next()} exactly once
    \item Each \texttt{next()} performs:
    \begin{itemize}
        \item One extractMin(): $O(\log k)$
        \item Zero or one insert(): $O(\log k)$
    \end{itemize}
    \item Total: $N \times O(\log k) = O(N \log k)$
\end{itemize}
\end{proof}

\section{Space Complexity}

\begin{theorem}[Space Complexity]
The heap-based collating iterator uses $O(k)$ auxiliary space.
\end{theorem}

\begin{proof}
\begin{itemize}
    \item Heap stores at most $k$ elements (one per iterator)
    \item Array-based heap: $k$ entries $\times$ (element reference + iterator reference)
    \item At 64-bit: $k \times 16$ bytes $= 16k$ bytes
    \item Input iterators provided by caller (not counted in auxiliary space)
    \item No other significant storage
    \item Total: $O(k)$
\end{itemize}
\end{proof}

\section{Correctness Proof}

\subsection{Loop Invariant}

\begin{invariant}[Heap Invariant]
At the start of each \texttt{next()} call:
\begin{enumerate}
    \item The heap $H$ contains exactly one element from each non-exhausted input iterator
    \item Each element in $H$ is the minimum remaining element from its source iterator
    \item All elements output so far form a non-decreasing sequence
    \item The minimum element in $H$ is the global minimum across all remaining elements
\end{enumerate}
\end{invariant}

\subsection{Proof of Correctness}

\begin{proof}[Proof by Induction]
\textbf{Base Case (Initialization):}
\begin{itemize}
    \item Extract first element from each non-empty iterator
    \item Insert into heap
    \item Heap size $= $ number of non-empty iterators $\leq k$
    \item Each heap element is the first (minimum) of its iterator
    \item No elements output yet (vacuously sorted)
    \item Invariant holds \checkmark
\end{itemize}

\textbf{Inductive Step (Maintenance):}

Assume invariant holds at start of iteration $i$. After extractMin() and potential insert():

\begin{itemize}
    \item Let $e = $ extractMin() from heap
    \item By heap property: $e \leq $ all other elements in $H$
    \item By invariant part (2): elements in $H$ are minimums of their iterators
    \item Therefore: $e \leq $ all remaining elements globally
    \item By invariant part (3): previous output sorted
    \item By transitivity: $e \geq $ previous output (since $e$ was minimum then)
    \item Appending $e$ maintains sorted output \checkmark

    \item After extracting $e$ from iterator $I$:
    \begin{itemize}
        \item If $I$ not exhausted: insert next element from $I$
        \item This element is new minimum of $I$ (since $I$ sorted)
        \item If $I$ exhausted: no insertion (removes $I$ from consideration)
    \end{itemize}
    \item Heap still has one element per non-exhausted iterator \checkmark
    \item Invariant maintained
\end{itemize}

\textbf{Termination:}
\begin{itemize}
    \item Iteration ends when heap empty
    \item Heap empty $\Leftrightarrow$ all iterators exhausted (by invariant part 1)
    \item All $N$ elements extracted (conservation of elements)
    \item Output is sorted (invariant part 3 throughout)
\end{itemize}

Therefore, the algorithm is correct. $\square$
\end{proof}

\section{Constant Factors}

\subsection{Comparison Operations}

For each \texttt{next()} call:
\begin{itemize}
    \item extractMin() sift-down: $\sim 2 \log_2 k$ comparisons
    \item insert() sift-up: $\sim \log_2 k$ comparisons
    \item Total per element: $\sim 3 \log_2 k$ comparisons
\end{itemize}

Practical examples:
\begin{itemize}
    \item $k = 2$: 3 comparisons (binary merge)
    \item $k = 10$: 10 comparisons
    \item $k = 100$: 20 comparisons
    \item $k = 1000$: 30 comparisons
\end{itemize}

\subsection{Memory Access Pattern}

Array-based heap (zero-indexed):
\begin{itemize}
    \item Parent of node $i$: $\lfloor (i-1)/2 \rfloor$
    \item Children of node $i$: $2i+1, 2i+2$
\end{itemize}

For $k = 100$:
\begin{itemize}
    \item Heap fits in $\sim 13$ cache lines (64-byte lines)
    \item Entire structure in L1 cache (32KB typical)
    \item Sequential array access (prefetcher friendly)
    \item $\sim 3 \log_2 k \approx 20$ memory accesses per element
\end{itemize}

\subsection{Branch Mispredictions}

\begin{itemize}
    \item Heap path unpredictable: $\log_2 k$ branches
    \item Each has $\sim 50\%$ misprediction rate (data-dependent)
    \item Modern CPUs: $\sim 15$-20 cycle penalty per mispredict
    \item For $k = 100$: $\sim 3-4$ mispredicts per element
\end{itemize}

\section{Lower Bound}

\begin{theorem}[Comparison Lower Bound]
Any comparison-based k-way merge algorithm requires $\Omega(N \log k)$ comparisons.
\end{theorem}

\begin{proof}[Proof Sketch]
\begin{itemize}
    \item For each element output, must determine which of $k$ iterators supplies it
    \item Decision tree has $k$ choices per element
    \item Height of decision tree: $\log_2 k$
    \item Must make decision for each of $N$ elements
    \item Total: $\Omega(N \log k)$ comparisons required
\end{itemize}

Therefore, heap-based algorithm is asymptotically optimal. $\square$
\end{proof}

\section{References}

\begin{itemize}
    \item Knuth, \textit{The Art of Computer Programming, Vol 3: Sorting and Searching}, Section 5.4.1
    \item Cormen et al., \textit{Introduction to Algorithms} (CLRS), Chapter 6: Heapsort
    \item Knuth TAOCP Vol 1, Section 2.2.3: Trees
\end{itemize}

\end{document}
